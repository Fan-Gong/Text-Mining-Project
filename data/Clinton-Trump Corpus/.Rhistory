geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Word Frequency %', title = '') +
coord_flip()
trump_part = wf %>% filter(x.vs.y == 'x<y') %>% top_n(10, wt = keyness)
ggplot(data = trump_part, aes(word, percent.y)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Word Frequency %') +
coord_flip()
ggplot(data = clinton_part, aes(word, freq.x)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Word Frequency %', title = '') +
coord_flip()
ggplot(data = clinton_part, aes(word, freq.x)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Word Frequency', title = '') +
theme_classic()
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = '') +
theme_classic()
View(clinton_part)
View(clinton_part)
clinton_part = wf %>% filter(x.vs.y == 'x>y') %>% top_n(10, wt = keyness)
View(clinton_part)
clintoo_part$word = factor(clintoo_part$word, levels = clinton_part$word[order(clinton_part$keyness, decreasing = T)])
clinton_part$word = factor(clintoo_part$word, levels = clinton_part$word[order(clinton_part$keyness, decreasing = T)])
clinton_part$word = factor(clinton_part$word, levels = clinton_part$word[order(clinton_part$keyness, decreasing = T)])
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = '') +
theme_classic()
trump_part = wf %>% filter(x.vs.y == 'x<y') %>% top_n(10, wt = keyness)
trump_part$word = factor(trump_part$word, levels = trump_part$word[order(trump_part$keyness, decreasing = T)])
ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness') +
coord_flip()
ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness') +
theme_classic()
library(gridExtra)
w1 = wordcloud(wf.a$word, wf.a$freq, min.freq = 50, random.order = F, scale = c(4, 0.3), colors = colors, use.r.layout=T)
p1 = ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = '') +
theme_classic()
p2 = ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness') +
theme_classic()
grid.arrange(p1, p2, ncol=2)
library(cowplot)
plot_grid(p1,p2)
plot_grid(p1,p2, align = 'h')
?plot_grid
wf = merge(wf.a,wf.b,by="word", all=TRUE)
wf[is.na(wf)] = 0
#calculate totals and normalized frequencies
total.a = sum(wf.a$freq)
total.b = sum(wf.b$freq)
normalize.a = function (frequency.a) {
normal.a = (frequency.a/total.a)*100
return(normal.a)
}
percent.x = mapply(normalize.a, wf$freq.x)
wf$percent.x = percent.x
normalize.b = function (frequency.b) {
normal.b = (frequency.b/total.b)*100
return(normal.b)
}
percent.y = mapply(normalize.b, wf$freq.y)
wf$percent.y = percent.y
#calculate keyness
log.like = function(frequency.a, frequency.b) {
expected.a = total.a*((frequency.a+frequency.b)/(total.a+total.b))
expected.b = total.b*((frequency.a+frequency.b)/(total.a+total.b))
L1 = if(frequency.a == 0) 0 else (frequency.a*log(frequency.a/expected.a))
L2 = if(frequency.b == 0) 0 else (frequency.b*log(frequency.b/expected.b))
likelihood = 2*(L1 + L2)
return(likelihood)
}
keyness = mapply(log.like, wf$freq.x, wf$freq.y)
wf$keyness = keyness
compare = function (x,y) {
if(x > y) return("x>y")
if(x < y) return("x<y")
if (x==y) return ("x=y")
}
x.vs.y = mapply(compare, wf$percent.x, wf$percent.y)
wf$x.vs.y = x.vs.y
wf = wf[with(wf, order(-keyness)), ]
#Visualization for the differences between these two corpus
clinton_part = wf %>% filter(x.vs.y == 'x>y') %>% top_n(10, wt = keyness)
clinton_part$word = factor(clinton_part$word, levels = clinton_part$word[order(clinton_part$keyness, decreasing = T)])
p1 = ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = ' ') +
theme_classic()
trump_part = wf %>% filter(x.vs.y == 'x<y') %>% top_n(10, wt = keyness)
trump_part$word = factor(trump_part$word, levels = trump_part$word[order(trump_part$keyness, decreasing = T)])
p2 = ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness') +
theme_classic()
plot_grid(p1,p2, align = 'h')
plot_grid(p1,p2, align = 'h', axis = 'b')
plot_grid(p1,p2, align = 'h', axis = 'r')
plot_grid(p1,p2, align = 'h', axis = 'r', ncol = 2)
plot_grid(p1,p2, align = 'h', ncol = 2)
plot_grid(p1,p2, align = 'h', ncol = 2, rel_widths = c(2,1))
plot_grid(p1,p2, align = 'h', ncol = 2, rel_widths = c(2,2))
plot_grid(p1,p2, align = 'h', ncol = 2, scale = 2)
plot_grid(p1,p2, align = 'h', ncol = 2, scale = 0.5)
plot_grid(p1,p2, align = 'h', ncol = 2, scale = 1)
plot_grid(p1,p2, align = 'h', ncol = 2, scale = 1.2)
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = ' ') +
theme_classic()
ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = "Key words in Donald's Speech") +
theme_classic()
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme_classic()
wf = merge(wf.a,wf.b,by="word", all=TRUE)
wf[is.na(wf)] = 0
#calculate totals and normalized frequencies
total.a = sum(wf.a$freq)
total.b = sum(wf.b$freq)
normalize.a = function (frequency.a) {
normal.a = (frequency.a/total.a)*100
return(normal.a)
}
percent.x = mapply(normalize.a, wf$freq.x)
wf$percent.x = percent.x
normalize.b = function (frequency.b) {
normal.b = (frequency.b/total.b)*100
return(normal.b)
}
percent.y = mapply(normalize.b, wf$freq.y)
wf$percent.y = percent.y
#calculate keyness
log.like = function(frequency.a, frequency.b) {
expected.a = total.a*((frequency.a+frequency.b)/(total.a+total.b))
expected.b = total.b*((frequency.a+frequency.b)/(total.a+total.b))
L1 = if(frequency.a == 0) 0 else (frequency.a*log(frequency.a/expected.a))
L2 = if(frequency.b == 0) 0 else (frequency.b*log(frequency.b/expected.b))
likelihood = 2*(L1 + L2)
return(likelihood)
}
keyness = mapply(log.like, wf$freq.x, wf$freq.y)
wf$keyness = keyness
compare = function (x,y) {
if(x > y) return("x>y")
if(x < y) return("x<y")
if (x==y) return ("x=y")
}
x.vs.y = mapply(compare, wf$percent.x, wf$percent.y)
wf$x.vs.y = x.vs.y
wf = wf[with(wf, order(-keyness)), ]
#Visualization for the differences between these two corpus
clinton_part = wf %>% filter(x.vs.y == 'x>y') %>% top_n(10, wt = keyness)
clinton_part$word = factor(clinton_part$word, levels = clinton_part$word[order(clinton_part$keyness, decreasing = T)])
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme_classic()
trump_part = wf %>% filter(x.vs.y == 'x<y') %>% top_n(10, wt = keyness)
trump_part$word = factor(trump_part$word, levels = trump_part$word[order(trump_part$keyness, decreasing = T)])
ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = "Key words in Donald's Speech") +
theme_classic()
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme_classic()
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme_classic()
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
scale_x_discrete(color = 'red')
?scale_x_discrete
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(colour="red")) +
theme_classic()
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="red"))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="red", size = 0.5))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="red", size = 2))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="red", size = 20))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="red", size = 14))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="red", size = 8))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'olivedrab2') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="red", size = 10))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'darkolivegreen1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="red", size = 10))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'darkolivegreen1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="deepskyblue", size = 12))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'darkolivegreen1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="dark2", size = 10))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'darkolivegreen1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="darkblue", size = 10))
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'darkolivegreen1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="darkblue", size = 10),
axis.text.y=element_text(color="darkblue"))
ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = "Key words in Donald's Speech") +
theme_classic()
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'darkolivegreen1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="darkblue", size = 10),
axis.text.y=element_text(color="darkblue"))
ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = "Key words in Donald's Speech") +
theme_classic()
ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = "Key words in Donald's Speech")
p1=ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'darkolivegreen1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="darkblue", size = 10),
axis.text.y=element_text(color="darkblue"))
p2=ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = "Key words in Donald's Speech")
plot_grid(p1,p2)
wf = merge(wf.a,wf.b,by="word", all=TRUE)
wf[is.na(wf)] = 0
#calculate totals and normalized frequencies
total.a = sum(wf.a$freq)
total.b = sum(wf.b$freq)
normalize.a = function (frequency.a) {
normal.a = (frequency.a/total.a)*100
return(normal.a)
}
percent.x = mapply(normalize.a, wf$freq.x)
wf$percent.x = percent.x
normalize.b = function (frequency.b) {
normal.b = (frequency.b/total.b)*100
return(normal.b)
}
percent.y = mapply(normalize.b, wf$freq.y)
wf$percent.y = percent.y
#calculate keyness
log.like = function(frequency.a, frequency.b) {
expected.a = total.a*((frequency.a+frequency.b)/(total.a+total.b))
expected.b = total.b*((frequency.a+frequency.b)/(total.a+total.b))
L1 = if(frequency.a == 0) 0 else (frequency.a*log(frequency.a/expected.a))
L2 = if(frequency.b == 0) 0 else (frequency.b*log(frequency.b/expected.b))
likelihood = 2*(L1 + L2)
return(likelihood)
}
keyness = mapply(log.like, wf$freq.x, wf$freq.y)
wf$keyness = keyness
compare = function (x,y) {
if(x > y) return("x>y")
if(x < y) return("x<y")
if (x==y) return ("x=y")
}
x.vs.y = mapply(compare, wf$percent.x, wf$percent.y)
wf$x.vs.y = x.vs.y
wf = wf[with(wf, order(-keyness)), ]
#Visualization for the differences between these two corpus
clinton_part = wf %>% filter(x.vs.y == 'x>y') %>% top_n(10, wt = keyness)
clinton_part$word = factor(clinton_part$word, levels = clinton_part$word[order(clinton_part$keyness, decreasing = T)])
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'darkolivegreen1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="darkblue", size = 10),
axis.text.y=element_text(color="darkblue"))
trump_part = wf %>% filter(x.vs.y == 'x<y') %>% top_n(10, wt = keyness)
trump_part$word = factor(trump_part$word, levels = trump_part$word[order(trump_part$keyness, decreasing = T)])
ggplot(data = trump_part, aes(word, keyness)) +
geom_col(fill = 'cornflowerblue') +
labs(x = NULL, y = 'Keyness', title = "Key words in Donald's Speech")
ggplot(data = clinton_part, aes(word, keyness)) +
geom_col(fill = 'darkolivegreen1') +
labs(x = NULL, y = 'Keyness', title = "Key words in Hillary's Speech") +
theme(axis.text.x=element_text(color="darkblue", size = 10),
axis.text.y=element_text(color="darkblue"))
df_readability = data.frame(
Name = c('Hillary Clinton', 'Donald Trump', 'Barack Obama', 'Grorge Bush', 'Bill Clinton', 'Abraham Lincoln'),
Grade = c(clinton.readability@Flesch.Kincaid$grade, trump.readability@Flesch.Kincaid$grade, obama.readability@Flesch.Kincaid$grade, bush.readability@Flesch.Kincaid$grade, bill_clinton.readability@Flesch.Kincaid$grade, lincoln.readability@Flesch.Kincaid$grade),
Age = c(clinton.readability@Flesch.Kincaid$age, trump.readability@Flesch.Kincaid$age, obama.readability@Flesch.Kincaid$age, bush.readability@Flesch.Kincaid$age, bill_clinton.readability@Flesch.Kincaid$age, lincoln.readability@Flesch.Kincaid$age))
df_readability %>% melt(id.vars = 'Name') %>%
ggplot(aes(x = variable, y = value, fill = factor(Name))) +
geom_col(position = 'dodge') +
scale_fill_brewer('Name', palette = 'Spectral') +
geom_text(aes(label = floor(value)), position = position_dodge(0.9), vjust = -0.25)
#Compare the readability between Clinton and Trump
##Tokenize the target text
clinton_tokenize = tokenize('../data/Clinton-Trump Corpus/Clinton', lang = 'en')
trump_tokenize = tokenize('../data/Clinton-Trump Corpus/Trump', lang = 'en')
##Calculate the Readability
clinton.readability = koRpus::readability(clinton_tokenize, index = 'Flesch.Kincaid', quiet = T)
trump.readability = koRpus::readability(trump_tokenize, index = 'Flesch.Kincaid', quiet = T)
clinton.readability@Flesch.Kincaid
trump.readability@Flesch.Kincaid
##Tokenize five presidents's text
obama_tokenize = tokenize('../data/InauguralSpeeches/Barack Obama', lang = 'en')
bush_tokenize = tokenize('../data/InauguralSpeeches/George Bush', lang = 'en')
bill_clinton_tokenize = tokenize('../data/InauguralSpeeches/Bill Clinton', lang = 'en')
lincoln_tokenize = tokenize('../data/InauguralSpeeches/Abraham Lincoln', lang = 'en')
##Calculate the readability
obama.readability = koRpus::readability(obama_tokenize, index = 'Flesch.Kincaid', quiet = T)
bush.readability = koRpus::readability(bush_tokenize, index = 'Flesch.Kincaid', quiet = T)
bill_clinton.readability = koRpus::readability(bill_clinton_tokenize, index = 'Flesch.Kincaid', quiet = T)
lincoln.readability = koRpus::readability(lincoln_tokenize, index = 'Flesch.Kincaid', quiet = T)
#Generate a data frame to store all these information
df_readability = data.frame(
Name = c('Hillary Clinton', 'Donald Trump', 'Barack Obama', 'Grorge Bush', 'Bill Clinton', 'Abraham Lincoln'),
Grade = c(clinton.readability@Flesch.Kincaid$grade, trump.readability@Flesch.Kincaid$grade, obama.readability@Flesch.Kincaid$grade, bush.readability@Flesch.Kincaid$grade, bill_clinton.readability@Flesch.Kincaid$grade, lincoln.readability@Flesch.Kincaid$grade),
Age = c(clinton.readability@Flesch.Kincaid$age, trump.readability@Flesch.Kincaid$age, obama.readability@Flesch.Kincaid$age, bush.readability@Flesch.Kincaid$age, bill_clinton.readability@Flesch.Kincaid$age, lincoln.readability@Flesch.Kincaid$age))
#visualization
##sort the data frame
df_readability$Name = factor(df_readability$Name, levels = df_readability$Name[order(df_readability$Age, decreasing = T)])
df_readability %>% melt(id.vars = 'Name') %>%
ggplot(aes(x = variable, y = value, fill = factor(Name))) +
geom_col(position = 'dodge') +
scale_fill_brewer('Name', palette = 'Spectral') +
geom_text(aes(label = floor(value)), position = position_dodge(0.9), vjust = -0.25)
#Load The File
setwd('../data/Clinton-Trump Corpus')
clinton1 = paste(readLines("Clinton/1.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton2 = paste(readLines("Clinton/2.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton3 = paste(readLines("Clinton/3.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton4 = paste(readLines("Clinton/4.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton5 = paste(readLines("Clinton/5.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton6 = paste(readLines("Clinton/6.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton7 = paste(readLines("Clinton/7.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton8 = paste(readLines("Clinton/8.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton9 = paste(readLines("Clinton/9.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton10 = paste(readLines("Clinton/10.txt", n=-1, skipNul=TRUE), collapse=" ")
trump1 = paste(readLines("Trump/1.txt", n=-1, skipNul=TRUE), collapse=" ")
trump2 = paste(readLines("Trump/2.txt", n=-1, skipNul=TRUE), collapse=" ")
trump3 = paste(readLines("Trump/3.txt", n=-1, skipNul=TRUE), collapse=" ")
trump4 = paste(readLines("Trump/4.txt", n=-1, skipNul=TRUE), collapse=" ")
trump5 = paste(readLines("Trump/5.txt", n=-1, skipNul=TRUE), collapse=" ")
trump6 = paste(readLines("Trump/6.txt", n=-1, skipNul=TRUE), collapse=" ")
trump7 = paste(readLines("Trump/7.txt", n=-1, skipNul=TRUE), collapse=" ")
trump8 = paste(readLines("Trump/8.txt", n=-1, skipNul=TRUE), collapse=" ")
trump9 = paste(readLines("Trump/9.txt", n=-1, skipNul=TRUE), collapse=" ")
trump10 = paste(readLines("Trump/10.txt", n=-1, skipNul=TRUE), collapse=" ")
sentiment.summary %>% select(-c(negative, positive, sentiment_score)) %>% melt(id.vars = 'Name') %>% filter(Name == 'Hillary Clinton') %>% ggplot(aes(x = variable, y = value, fill = factor(variable))) +
geom_col() +
labs(x = NULL, y = 'Mean Emotion Score for Hillary Clinton') +
coord_flip() +
scale_fill_discrete('Sentiment')
#Two methods to quantify the sentiment of each sentence (get_sentiment/get_nrc_sentiment)
sentence.list = NULL
for(i in 1:nrow(speech.list)){
sentences = sent_detect(speech.list$fulltext[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions = get_nrc_sentiment(sentences)
sentiment_score = as.numeric(get_sentiment(sentences))
word.count = word_count(sentences)
emotions = diag(1/(word.count+0.01))%*%as.matrix(emotions)
sentence.list = rbind(sentence.list,
cbind(speech.list[i,-ncol(speech.list)],
sentences = as.character(sentences),
word.count,
sentiment_score = sentiment_score,
emotions,
sent.id = 1:length(sentences)
))
}
}
#Load The File
setwd('../data/Clinton-Trump Corpus')
clinton1 = paste(readLines("Clinton/1.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton2 = paste(readLines("Clinton/2.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton3 = paste(readLines("Clinton/3.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton4 = paste(readLines("Clinton/4.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton5 = paste(readLines("Clinton/5.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton6 = paste(readLines("Clinton/6.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton7 = paste(readLines("Clinton/7.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton8 = paste(readLines("Clinton/8.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton9 = paste(readLines("Clinton/9.txt", n=-1, skipNul=TRUE), collapse=" ")
clinton10 = paste(readLines("Clinton/10.txt", n=-1, skipNul=TRUE), collapse=" ")
trump1 = paste(readLines("Trump/1.txt", n=-1, skipNul=TRUE), collapse=" ")
trump2 = paste(readLines("Trump/2.txt", n=-1, skipNul=TRUE), collapse=" ")
trump3 = paste(readLines("Trump/3.txt", n=-1, skipNul=TRUE), collapse=" ")
trump4 = paste(readLines("Trump/4.txt", n=-1, skipNul=TRUE), collapse=" ")
trump5 = paste(readLines("Trump/5.txt", n=-1, skipNul=TRUE), collapse=" ")
trump6 = paste(readLines("Trump/6.txt", n=-1, skipNul=TRUE), collapse=" ")
trump7 = paste(readLines("Trump/7.txt", n=-1, skipNul=TRUE), collapse=" ")
trump8 = paste(readLines("Trump/8.txt", n=-1, skipNul=TRUE), collapse=" ")
trump9 = paste(readLines("Trump/9.txt", n=-1, skipNul=TRUE), collapse=" ")
trump10 = paste(readLines("Trump/10.txt", n=-1, skipNul=TRUE), collapse=" ")
#Clinton Speeches Data Frame
clinton.speeches=data.frame(
Name = rep ("Hillary Clinton", 10),
File = paste0('clinton', 1:10),
Words=c(word_count(clinton1),word_count(clinton2),word_count(clinton3),word_count(clinton4),word_count(clinton5),word_count(clinton6),word_count(clinton7),word_count(clinton8),word_count(clinton9),word_count(clinton10)),
fulltext=c(clinton1,clinton2,clinton3,clinton4,clinton5,clinton6,clinton7,clinton8,clinton9,clinton10)
)
#Trump Speeches Data Frame
trump.speeches=data.frame(
Name = rep ("Donald Trump", 10),
File = paste0('trump', 1:10),
Words=c(word_count(trump1),word_count(trump2),word_count(trump3),word_count(trump4),word_count(trump5),word_count(trump6),word_count(trump7),word_count(trump8),word_count(trump9),word_count(trump10)),
fulltext=c(trump1,trump2,trump3,trump4,trump5,trump6,trump7,trump8,trump9,trump10)
)
#Complete Data Frame
speech.list=rbind(clinton.speeches, trump.speeches)
#Two methods to quantify the sentiment of each sentence (get_sentiment/get_nrc_sentiment)
sentence.list = NULL
for(i in 1:nrow(speech.list)){
sentences = sent_detect(speech.list$fulltext[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions = get_nrc_sentiment(sentences)
sentiment_score = as.numeric(get_sentiment(sentences))
word.count = word_count(sentences)
emotions = diag(1/(word.count+0.01))%*%as.matrix(emotions)
sentence.list = rbind(sentence.list,
cbind(speech.list[i,-ncol(speech.list)],
sentences = as.character(sentences),
word.count,
sentiment_score = sentiment_score,
emotions,
sent.id = 1:length(sentences)
))
}
}
#Some non-sentences exist in raw data due to erroneous extra end-of sentence marks
sentence.list = sentence.list %>% filter(!is.na(word.count))
sentiment.summary = tbl_df(sentence.list) %>%
group_by(Name) %>%
summarise(
anger=mean(anger),
anticipation=mean(anticipation),
disgust=mean(disgust),
fear=mean(fear),
joy=mean(joy),
sadness=mean(sadness),
surprise=mean(surprise),
trust=mean(trust),
negative=mean(negative),
positive=mean(positive),
sentiment_score = mean(sentiment_score)
)
sentiment.summary %>% select(-c(negative, positive, sentiment_score)) %>% melt(id.vars = 'Name') %>% filter(Name == 'Hillary Clinton') %>% ggplot(aes(x = variable, y = value, fill = factor(variable))) +
geom_col() +
labs(x = NULL, y = 'Mean Emotion Score for Hillary Clinton') +
coord_flip() +
scale_fill_discrete('Sentiment')
sentiment.summary %>% select(-c(negative, positive, sentiment_score)) %>% melt(id.vars = 'Name') %>% filter(Name == 'Hillary Clinton') %>% ggplot(aes(x = variable, y = value, fill = factor(variable))) +
geom_col() +
labs(x = NULL, y = 'Mean Emotion Score for Hillary Clinton') +
coord_flip() +
scale_fill_discrete('Sentiment', palette = 'Spectral')
sentiment.summary %>% select(-c(negative, positive, sentiment_score)) %>% melt(id.vars = 'Name') %>% filter(Name == 'Hillary Clinton') %>% ggplot(aes(x = variable, y = value, fill = factor(variable))) +
geom_col() +
labs(x = NULL, y = 'Mean Emotion Score for Hillary Clinton') +
coord_flip() +
scale_fill_brewer('Sentiment', palette = 'Spectral')
sentiment.summary %>% select(-c(negative, positive, sentiment_score)) %>% melt(id.vars = 'Name') %>% filter(Name == 'Donald Trump') %>% ggplot(aes(x = variable, y = value, fill = factor(variable))) +
geom_col() +
labs(x = NULL, y = 'Mean Emotion Score for Donald Trump') +
coord_flip() +
scale_fill_brewer('Sentiment', palette = 'Spectral')
#the emotionally charged sentences
speech.df = tbl_df(sentence.list)%>%
filter(Name =="Hillary Clinton", word.count>=4)%>%
select(sentences, anger:trust)
speech.df = as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])
